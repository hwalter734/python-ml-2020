{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ones  sex  sat_sum  hs_gpa  fy_gpa\n",
       "0     1    1      127    3.40    3.18\n",
       "1     1    2      122    4.00    3.33\n",
       "2     1    2      116    3.75    3.25\n",
       "3     1    1       95    3.75    2.42\n",
       "4     1    1      107    4.00    2.63"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ones</th>\n      <th>sex</th>\n      <th>sat_sum</th>\n      <th>hs_gpa</th>\n      <th>fy_gpa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>127</td>\n      <td>3.40</td>\n      <td>3.18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>122</td>\n      <td>4.00</td>\n      <td>3.33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2</td>\n      <td>116</td>\n      <td>3.75</td>\n      <td>3.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>95</td>\n      <td>3.75</td>\n      <td>2.42</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>107</td>\n      <td>4.00</td>\n      <td>2.63</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "df = pd.read_csv('satgpa.csv')\n",
    "df.insert(loc=0, column='ones', value=1) #Agregamos la columna de unos\n",
    "df.drop(['sat_v', 'sat_m'], axis=1, inplace=True)\n",
    "df.head()\n",
    "# Dejamos solo las columnas de interés que son: sexo, total de percentil de SAT verbal y matemática, y el promedio GPA en highschool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = df.pop('fy_gpa').to_numpy()\n",
    "x_columns = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[  1.  ,   1.  , 127.  ,   3.4 ],\n",
       "       [  1.  ,   2.  , 122.  ,   4.  ],\n",
       "       [  1.  ,   2.  , 116.  ,   3.75],\n",
       "       ...,\n",
       "       [  1.  ,   1.  , 114.  ,   3.5 ],\n",
       "       [  1.  ,   1.  , 120.  ,   2.3 ],\n",
       "       [  1.  ,   1.  ,  93.  ,   2.7 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "x_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = x_columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "x_columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function_grades(X, y, theta):\n",
    "    h = X @ theta\n",
    "    return ((y - h) ** 2).sum() / (2 * len(X))\n",
    "\n",
    "def linear_gradient_grades(X, y, theta):\n",
    "    h = X @ theta\n",
    "    return (X.T @ (h - y)) / len(X)\n",
    "\n",
    "def gradient_descent_grades(X, y, theta_0, linear_function, linear_gradient, learning_rate=0.01, threshold= 0.001, max_iter=1000):\n",
    "    theta = theta_0\n",
    "    iteration = 0\n",
    "    grades = []\n",
    "\n",
    "    while np.linalg.norm(linear_gradient(X, y, theta)) > threshold and iteration < max_iter:\n",
    "        iteration += 1\n",
    "        theta = theta - (learning_rate * linear_gradient(X, y, theta))\n",
    "        grades.append(linear_function(X, y, theta))\n",
    "    return theta, grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.30494045],\n",
       "       [0.82025886],\n",
       "       [0.88290934],\n",
       "       [0.96776218]])"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "random_theta = np.random.rand(n,1)\n",
    "random_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4441821.499040509\n"
     ]
    }
   ],
   "source": [
    "print(linear_function_grades(x_columns, y_column, random_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  92.66734391   92.51734391   92.59734391 ...   92.67734391\n    93.90734391   93.46734391]\n [ 136.67745762  136.45485762  136.57357762 ...  136.69229762\n   138.51761762  137.86465762]\n [9757.4882721  9741.9889221  9750.2552421  ... 9758.5215621\n  9885.6162321  9840.1514721 ]\n [ 299.61481976  299.13510476  299.39095276 ...  299.64680076\n   303.58046376  302.17329976]]\n"
     ]
    }
   ],
   "source": [
    "print(linear_gradient_grades(x_columns, y_column, random_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(array([[-inf, -inf, -inf, ..., -inf, -inf, -inf],\n       [-inf, -inf, -inf, ..., -inf, -inf, -inf],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan]]), [51750517403.672325, 602964819680582.8, 7.025370831097003e+18, 8.185524876989356e+22, 9.537264170487812e+26, 1.111222667142214e+31, 1.2947274961636069e+35, 1.508535902739596e+39, 1.757652151975929e+43, 2.047906902139469e+47, 2.3860936733788444e+51, 2.7801278525847787e+55, 3.2392319559578697e+59, 3.77415148542298e+63, 4.397406431089728e+67, 5.123584306267486e+71, 5.969681573628194e+75, 6.955501453723028e+79, 8.104117426708882e+83, 9.44241327571461e+87, 1.1001712311762419e+92, 1.281851050748726e+96, 1.4935330698920885e+100, 1.740171784825058e+104, 2.027539866204653e+108, 2.3623632706252962e+112, 2.7524786641290825e+116, 3.2070168422828926e+120, 3.7366164398372963e+124, 4.353672931921176e+128, 5.0726287547373904e+132, 5.91031133614207e+136, 6.8863269478386785e+140, 8.023519597443642e+144, 9.348505700962588e+148, 1.0892297049885014e+153, 1.2691026653673376e+157, 1.4786794446259472e+161, 1.722865265062245e+165, 2.00737538642722e+169, 2.3388688737004917e+173, 2.7251044549775043e+177, 3.1751221173800687e+181, 3.6994546913099166e+185, 4.310374375253276e+189, 5.022179971140942e+193, 5.851531553114147e+197, 6.817840402742811e+201, 7.943723337274737e+205, 9.255532064636927e+209, 1.0783969954939473e+214, 1.2564810664247772e+218, 1.4639735430279263e+222, 1.7057308637241218e+226, 1.9874114483266575e+230, 2.3156081354571106e+234, 2.698002490380058e+238, 3.1435445948889106e+242, 3.662662527291909e+246, 4.26750643545505e+250, 4.972232915522118e+254, 5.7933363523013205e+258, 6.750034976463215e+262, 7.864720674361944e+266, 9.163483078445538e+270, 1.0676720204785912e+275, 1.243984992992654e+279, 1.4494138959427405e+283, 1.6887668690423822e+287, 1.9676460574570614e+291, 2.2925787320909056e+295, 2.6711700627846524e+299, 3.112281120138223e+303, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan])\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent_grades(X, y, theta_0, linear_function, linear_gradient, learning_rate=0.01, threshold= 0.001, max_iter=1000):\n",
    "    theta = theta_0\n",
    "    iteration = 0\n",
    "    grades = []\n",
    "\n",
    "    while np.linalg.norm(linear_gradient(X, y, theta)) > threshold and iteration < max_iter:\n",
    "        iteration += 1\n",
    "        theta = theta - (learning_rate * linear_gradient(X, y, theta))\n",
    "        grades.append(linear_function(X, y, theta))\n",
    "    return theta, grades\n",
    "    \n",
    "print(gradient_descent_grades(x_columns, y_column, random_theta, linear_function_grades, linear_gradient_grades))"
   ]
  }
 ]
}